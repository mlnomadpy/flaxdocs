---
sidebar_position: 1
---

# Advanced Research Techniques

Explore cutting-edge techniques for research with Flax.

This section covers advanced topics and implementations for research:

- **[Custom Training Loops](custom-training-loops.md)**: Build flexible training loops for research experiments, including flexible training state and advanced training steps.
- **[Contrastive Learning](contrastive-learning.md)**: Implement self-supervised learning methods like SimCLR.
- **[Meta-Learning](meta-learning.md)**: Implement Model-Agnostic Meta-Learning (MAML).
- **[Knowledge Distillation](knowledge-distillation.md)**: Transfer knowledge from a teacher model to a student model.
- **[Neural Architecture Search](neural-architecture-search.md)**: Implement differentiable architecture search (DARTS).
- **[Adversarial Training](adversarial-training.md)**: Robust training against adversarial examples using methods like FGSM.
- **[Curriculum Learning](curriculum-learning.md)**: Strategies to gradually increase task difficulty during training.
- **[Experiment Reproducibility](experiment-reproducibility.md)**: Best practices and utilities for ensuring reproducible research experiments.
- **[Streaming and Architectures](streaming-and-architectures.md)**: Train on datasets larger than memory and build advanced architectures like ResNet, BERT, and GPT.
